import base64
import gzip
import math
from contextlib import contextmanager
from dataclasses import dataclass
from typing import Dict, Iterable, Optional, Tuple

import numpy as np
import torch
import torch.nn.functional as F
from torch import Tensor, nn

class ModelDimensions:
    n_mels: int
    n_audio_ctx: int
    n_audio_state: int
    n_audio_head: int
    n_audio_layer: int

    n_vocab: int
    n_text_ctx: int
    n_text_state: int
    n_text_head: int
    n_text_layer: int

class Linear(nn.Module):
    """
    4D Linear å±‚ (B, C, T, 1)
    å®žè´¨æ˜¯ 1x1 Conv2dï¼š
        è¾“å…¥é€šé“ = in_features = C
        è¾“å‡ºé€šé“ = out_features
    """
    def __init__(self, in_features: int, out_features: int, bias: bool = True):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features

        # æ³¨æ„ï¼šæƒé‡æ˜¯å¯è®­ç»ƒå‚æ•°ï¼ˆæˆ–å¯å†»ç»“åŽå¯¼å‡ºï¼‰
        self.weight = nn.Parameter(
            torch.empty(out_features, in_features, 1, 1)
        )

        self.bias = nn.Parameter(torch.empty(out_features)) if bias else None

        nn.init.kaiming_uniform_(self.weight, a=5 ** 0.5)
        if self.bias is not None:
            fan_in = in_features
            bound = 1 / fan_in ** 0.5
            nn.init.uniform_(self.bias, -bound, bound)

    def forward(self, x: Tensor) -> Tensor:
        """
        è¾“å…¥:  x (B, C, T, 1)
        è¾“å‡º:  (B, out_features, T, 1)
        """
        if x.dim() != 4:
            raise ValueError(f"Expected 4D input (B,C,T,1), got {x.shape}")

        return F.conv2d(x, self.weight, self.bias)

class LayerNorm(nn.Module):
    """
    (B, C, T, 1) è¾“å…¥çš„ LayerNorm ç­‰ä»·å½¢å¼ (GroupNorm å®žçŽ°)ã€‚
    ä½¿ç”¨ GroupNorm(1, C) åœ¨æ ·æœ¬å†…éƒ¨è·¨æ‰€æœ‰é€šé“åšå½’ä¸€åŒ–ã€‚
    """
    def __init__(self, n_state: int, eps: float = 1e-5):
        super().__init__()
        self.norm = nn.GroupNorm(1, n_state, eps=eps, affine=True)

    def forward(self, x: Tensor) -> Tensor:
        """
        x: (B, C, T, 1)
        return: (B, C, T, 1)
        """
        if x.dim() != 4:
            raise ValueError(f"Expected 4D input (B,C,T,1), got {x.shape}")
        return self.norm(x)

class LayerNorm4D(nn.Module):
    """
    Hailo-friendly LN for (B, C, T, 1)
    - ä¸ç”¨ GroupNorm
    - ä¸ç”¨ **2 / Pow
    - åªåœ¨é€šé“ç»´ C ä¸Šåšå½’ä¸€åŒ–
    """
    def __init__(self, n_state: int, eps: float = 1e-5):
        super().__init__()
        self.eps = eps
        self.weight = nn.Parameter(torch.ones(1, n_state, 1, 1))
        self.bias   = nn.Parameter(torch.zeros(1, n_state, 1, 1))

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # x: (B, C, T, 1)
        # 1) æŒ‰é€šé“æ±‚å‡å€¼
        mean = x.mean(dim=1, keepdim=True)                # (B,1,T,1)

        # 2) æ–¹å·®ç”¨ä¹˜æ³•ï¼Œä¸ç”¨ **2
        diff = x - mean                                   # (B,C,T,1)
        diff_sq = diff * diff                             # (B,C,T,1)
        var = diff_sq.mean(dim=1, keepdim=True)           # (B,1,T,1)

        # 3) æ ‡å‡†åŒ–
        x_hat = (x - mean) / torch.sqrt(var + self.eps)   # (B,C,T,1)

        # 4) ä»¿å°„
        return x_hat * self.weight + self.bias
    
class RMSNorm4D(nn.Module):
    """
    4D ç‰ˆæœ¬ RMSNormï¼ŒæŒ‰é€šé“ç»´åº¦ C åšå½’ä¸€åŒ–ã€‚
    è¾“å…¥/è¾“å‡ºå½¢çŠ¶: (B, C, T, 1)
    """
    def __init__(self, n_state: int, eps: float = 1e-6):
        super().__init__()
        # GroupNorm(1, C) normalizes over all channels
        self.norm = nn.GroupNorm(1, n_state, eps=eps, affine=True)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.norm(x)
    
class SSM4D(nn.Module):
    """
    Hailo-friendly ç‰ˆæœ¬ SSMï¼š
    - åŠ¨æ€ kernelï¼ˆalpha, beta, thetaï¼‰ç…§ç®—ï¼›
    - ä¸ç”¨ F.conv2dï¼›
    - å…¨é™æ€ shapeï¼škernel_size=24, pad_top=23ï¼›
    - è¾“å…¥è¾“å‡ºæ’å®šä¸º 4D (B, C, T, 1)ã€‚
    """
    def __init__(self, n_state: int, kernel_size: int = 24):
        super().__init__()
        self.n_state = n_state
        self.kernel_size = int(kernel_size)
        time_indices = torch.arange(self.kernel_size).view(1, 1, self.kernel_size)
        self.register_buffer("time_indices", time_indices, persistent=False)

    def _cos_approx(self, x: Tensor) -> Tensor:
        # ä½¿ç”¨æ³°å‹’å±•å¼€è¿‘ä¼¼ cos(x) â‰ˆ 1 - x^2/2 + x^4/24
        x2 = x * x
        x4 = x2 * x2
        return 1.0 - 0.5 * x2 + (1.0 / 24.0) * x4

    def forward(self, x: Tensor, alpha: Tensor, beta: Tensor, theta: Tensor) -> Tensor:
        if x.dim() != 4:
            raise ValueError(f"Expected 4D input (B,C,T,1), got {x.shape}")

        B, C, T, _ = x.shape
        t_idx = self.time_indices.to(dtype=x.dtype, device=x.device)

        alpha = alpha.view(1, C, 1).to(dtype=x.dtype, device=x.device)
        beta = beta.view(1, C, 1).to(dtype=x.dtype, device=x.device)
        theta = theta.view(1, C, 1).to(dtype=x.dtype, device=x.device)

        log_alpha = torch.log(alpha.clamp(min=1e-6))
        decay = torch.exp(log_alpha * t_idx)                 # (1,C,K)
        phase = self._cos_approx(theta * t_idx)              # (1,C,K)
        kernel = (beta * decay * phase).view(C, 1, self.kernel_size)

        x_1d = x.squeeze(-1)
        x_padded = F.pad(x_1d, (self.kernel_size - 1, 0))
        y = F.conv1d(x_padded, kernel, groups=C)
        return y.unsqueeze(-1)

class Conv1x1NoUnsqueeze(nn.Conv2d):
    def forward(self, x):
        # å¼ºåˆ¶ weight ä¸º bufferï¼Œä¸èµ°å‚æ•°è·¯å¾„ â†’ ä¸è§¦å‘ Constantâ†’Unsqueeze
        weight = self.weight
        bias = self.bias
        return F.conv2d(x, weight, bias)

class MultiHeadAttention(nn.Module):
    """
    4Dç‰ˆæœ¬å¤šå¤´æ³¨æ„åŠ›ï¼Œä¿æŒ (B, C, T, 1)
    - è‡ªæ³¨æ„åŠ›: é‡‡ç”¨æ ¸æ³¨æ„åŠ›è¿‘ä¼¼ + å› æžœ cumsum
    - äº¤å‰æ³¨æ„åŠ›: ä½¿ç”¨æ ‡å‡†ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ï¼ˆæ”¯æŒä¸åŒé•¿åº¦çš„é”®å€¼åºåˆ—ï¼‰
    """
    def __init__(self, n_state: int, n_head: int):
        super().__init__()
        self.n_head = n_head
        self.n_state = n_state
        self.d_head = n_state // n_head

        self.query = Linear(n_state, n_state)
        self.key   = Linear(n_state, n_state, bias=False)
        self.value = Linear(n_state, n_state)
        self.out   = Linear(n_state, n_state)

    def phi(self, x: Tensor) -> Tensor:
        # æ­£å€¼æ ¸ï¼Œé˜²æ­¢å…¨ 0
        return F.silu(x) + 1.0

    def forward(self, x: Tensor, xa: Optional[Tensor] = None) -> Tensor:
        if x.dim() != 4:
            raise ValueError(f"Expected 4D input (B,C,T,1), got {x.shape}")

        if xa is None:
            q = self.query(x)   # (B, C, T, 1)
            k = self.key(x)     # (B, C, T, 1)
            v = self.value(x)   # (B, C, T, 1)
            out = self._self_attention_kernel(q, k, v)
            return self.out(out)
        else:
            q = self.query(x)
            k = self.key(xa)
            v = self.value(xa)
            out = self._cross_attention_linear(q, k, v)
            return self.out(out)

    def _self_attention_kernel(self, q: Tensor, k: Tensor, v: Tensor) -> Tensor:
        B, C, T, _ = q.shape
        H = self.n_head
        Dh = C // H

        # 1) æ ¸æ˜ å°„ + åˆ†å¤´
        phi_q = self.phi(q).reshape(B, H, Dh, T, 1)
        phi_k = self.phi(k).reshape(B, H, Dh, T, 1)
        v = v.reshape(B, H, Dh, T, 1)
        # 2) å…¨å±€èšåˆï¼ˆæ³¨æ„ä¸æ˜¯ cumsumï¼Œæ˜¯ sumï¼‰
        #    S_k  : Î£_t Ï†(k_t)
        #    S_kv : Î£_t Ï†(k_t) * v_t
        S_k  = torch.sum(phi_k, dim=3, keepdim=True)        # (B,H,Dh,1,1)
        S_kv = torch.sum(phi_k * v, dim=3, keepdim=True)    # (B,H,Dh,1,1)

        # 3) å¯¹æ¯ä¸ªæ—¶é—´æ­¥ç”¨å½“å‰çš„ Ï†(q_t) åŽ»â€œé€‰å–â€è¿™ä¸ªå…¨å±€èšåˆ
        #    åˆ†æ¯è¦åœ¨ Dh ä¸Šå†æ±‡æ€»ä¸€æ¬¡ï¼Œè¿™æ · phi_q å°±çœŸçš„èµ·ä½œç”¨äº†
        den = torch.sum(phi_q * S_k, dim=2, keepdim=True) + 1e-6   # (B,H,1,T,1)
        out = (phi_q * S_kv) / den                                 # (B,H,Dh,T,1)

        # 4) åˆå¹¶ heads
        out = out.reshape(B, C, T, 1)
        out = out / torch.sqrt(torch.tensor(Dh, dtype=out.dtype, device=out.device))
        return out
    
    def _cross_attention_linear(self, q: Tensor, k: Tensor, v: Tensor) -> Tensor:
        B, C, Tq, _ = q.shape
        _, _, Tk, _ = k.shape
        H = self.n_head
        Dh = C // H
        
        phi_q = self.phi(q).reshape(B, H, Dh, Tq, 1)
        phi_k = self.phi(k).reshape(B, H, Dh, Tk, 1)
        v = v.reshape(B, H, Dh, Tk, 1)

        # å¯¹ encoder çš„æ—¶é—´ç»´ Tk åšå…¨å±€èšåˆ
        k_sum  = torch.sum(phi_k, dim=3, keepdim=True)          # (B,H,Dh,1,1)
        kv_sum = torch.sum(phi_k * v, dim=3, keepdim=True)      # (B,H,Dh,1,1)

        den = torch.sum(phi_q * k_sum, dim=2, keepdim=True)     # (B,H,1,Tq,1)
        den = den + 1e-6
        out = (phi_q * kv_sum) / den                            # (B,H,Dh,Tq,1)

        # åˆå¹¶ heads å›žåˆ° 4D
        out = out.reshape(B, C, Tq, 1)
        out = out / torch.sqrt(torch.tensor(Dh, dtype=out.dtype, device=out.device))
        return out

class ResidualAttentionBlock(nn.Module):
    def __init__(self, n_state: int, n_head: int):
        super().__init__()

        self.attn = MultiHeadAttention(n_state, n_head)
        self.attn_ln = LayerNorm(n_state)

        n_mlp = n_state * 4
        self.mlp = nn.Sequential(
            Linear(n_state, n_mlp), nn.SiLU(), Linear(n_mlp, n_state)
        )
        self.mlp_ln = LayerNorm(n_state)

    def forward(
        self,
        x: Tensor,
    ):
        x = x + self.attn(self.attn_ln(x))
        x = x + self.mlp(self.mlp_ln(x))
        return x

class AudioEncoder(nn.Module):
    def __init__(self, n_mels: int, n_ctx: int, n_state: int, n_head: int, n_layer: int):
        super().__init__()
        self.conv1 = nn.Conv2d(
            in_channels=n_mels,
            out_channels=n_state,
            kernel_size=(3, 1),
            padding=(0, 0)
        )
        self.conv2 = nn.Conv2d(
            in_channels=n_state,
            out_channels=n_state,
            kernel_size=(3, 1),
            stride=(2, 1),
            padding=(0, 0)
        )
        self.blocks = nn.ModuleList(
            [ResidualAttentionBlock(n_state, n_head) for _ in range(n_layer)]
        )
        self.ln_post = LayerNorm(n_state)

    def forward(self, x: Tensor, pos_emb: Optional[Tensor] = None) -> Tensor:
        # ä½¿ç”¨é™æ€ F.pad æ›¿ä»£ conv çš„å¯¹ç§° paddingï¼Œé¿å… Hailo è‡ªåŠ¨æ‹† padding
        # conv1: kernel=(3,1), æœŸæœ›å¯¹ç§° pad 1 â†’ ä½¿ç”¨ F.pad pads=(0,0,1,1)
        # è¾“å…¥æ˜¯ B x 80 x 1000 x 1
        x = F.pad(x, (0, 0, 1, 1))
        x = F.silu(self.conv1(x)) # B x 80 x 1000 x 1 -> B x 768 x 1000 x 1

        # conv2: kernel=(3,1), stride=(2,1), å¯¹ç§° pad 1
        x = F.pad(x, (0, 0, 1, 1))
        x = F.silu(self.conv2(x))  # B x 768 x 1000 x 1 -> B x 768 x 500 x 1

        if pos_emb is not None:
            # æˆªåˆ°åŒæ ·çš„æ—¶é—´é•¿åº¦
            x = (x + pos_emb[..., :x.shape[2], :]).to(x.dtype)

        for block in self.blocks:
            x = block(x)

        return self.ln_post(x)
    
class MambaLikeBlock4D(nn.Module):
    """
    NPU / Hailo å‹å¥½çš„ Mamba é£Žæ ¼å—ã€‚
    å…³é”®æ”¹åŠ¨ï¼šä½¿ç”¨ F.pad(é™æ€ int) ä»£æ›¿ nn.ConstantPad2dï¼Œé¿å… ONNX å¯¼å‡ºäº§ç”Ÿ Padâ†’Cast
    é“¾å¯¼è‡´ Hailo è§£æž KeyError (å¦‚ Cast_output_0_value ç¼ºå¤±)ã€‚
    """
    def __init__(self, n_state: int, d_conv: int = 3, ssm_kernel: int = 24):
        super().__init__()
        self.n_state = n_state
        # ç¡®ä¿ä¸ºé™æ€ intï¼Œé¿å… ONNX å¯¼å‡ºæ—¶æ’å…¥ Cast
        self.d_conv_ks = int(d_conv)
        self.ln = RMSNorm4D(n_state)
        self.in_proj = Linear(n_state, 2 * n_state)

        # ä½¿ç”¨é™æ€æ•´æ•°è®°å½•æ‰€éœ€çš„å› æžœ paddingï¼ˆé¡¶ç«¯å¡«å……ï¼‰ï¼Œåœ¨ forward ä¸­ç”¨ F.pad å®žçŽ°
        # è¯´æ˜Žï¼šä½¿ç”¨ nn.ConstantPad2d åœ¨æŸäº› PyTorchâ†’ONNX å¯¼å‡ºè·¯å¾„ä¸‹ä¼šç”Ÿæˆ Padâ†’Cast é“¾ï¼Œ
        # Hailo è§£æžå™¨æ— æ³•è¯†åˆ«ä¸­é—´ Castï¼Œå¯¼è‡´ KeyErrorã€‚æ”¹ç”¨ F.pad å¯é¿å…è¯¥é—®é¢˜ã€‚
        self.pad_top = int(self.d_conv_ks - 1)

        # depthwise conv æœ¬èº«ä¸å¸¦ padding
        self.d_conv = nn.Conv2d(
            in_channels=2 * n_state,
            out_channels=2 * n_state,
            kernel_size=(d_conv, 1),
            padding=(0, 0),
            groups=2 * n_state,
        )

        self.ssm = SSM4D(n_state, kernel_size=ssm_kernel)
        self.out_proj = Linear(n_state, n_state)

        self.register_parameter(
            "alpha",
            nn.Parameter(torch.full((n_state,), 0.9, dtype=torch.float32))
        )
        self.register_parameter(
            "beta",
            nn.Parameter(torch.full((n_state,), 0.5, dtype=torch.float32))
        )
        theta_init = torch.linspace(0, math.pi / 4, n_state, dtype=torch.float32)
        self.register_parameter("theta", nn.Parameter(theta_init))

    def set_ssm_parameters(self, alpha: Tensor, beta: Tensor, theta: Tensor) -> None:
        with torch.no_grad():
            self.alpha.copy_(alpha.to(self.alpha.device, dtype=self.alpha.dtype))
            self.beta.copy_(beta.to(self.beta.device, dtype=self.beta.dtype))
            self.theta.copy_(theta.to(self.theta.device, dtype=self.theta.dtype))

    def forward(self, x: Tensor) -> Tensor:
        # x: (B,def forward(self, x: Tensor) -> Tensor:
        # x: (B, C, T, 1)
        B, C, T, _ = x.shape

        # ---- å‰å±‚æ ‡å‡†å¤„ç† ----
        h = self.ln(x)
        h = self.in_proj(h)  # (B,2C,T,1)

        # å› æžœ padï¼šé™æ€å¸¸æ•°ï¼Œé¿å…åŠ¨æ€ If/Pad
        if self.pad_top > 0:
            h = F.pad(h, (0, 0, int(self.pad_top), 0))  # (B,2C,T+pad_top,1)
        h = self.d_conv(h)  # (B,2C,T,1)

        # ---- æ‹†ä¸¤åŠ ----
        h_content = h[:, :C, :, :]
        h_gate    = h[:, C:, :, :]

        # ---- SSM è·¯å¾„ ----
        h_content = F.silu(h_content)
        alpha = self.alpha.to(dtype=h_content.dtype, device=h_content.device)
        beta  = self.beta .to(dtype=h_content.dtype, device=h_content.device)
        theta = self.theta.to(dtype=h_content.dtype, device=h_content.device)
        h_ssm = self.ssm(h_content, alpha, beta, theta)  # (B,C,T,1)

        # ---- Gate è·¯å¾„ ----
        gate = torch.sigmoid(h_gate).to(dtype=h_ssm.dtype)  # (B,C,T,1)

        # ==== ðŸ”’ å…³é”®éƒ¨åˆ† ====

        # 1. ç”¨ Add(0) â€œé”šå®šâ€ä¸¤æ¡è·¯å¾„ï¼Œé˜²æ­¢ Hailo æŠŠ Unsqueeze / Shape æŠ˜å æŽ‰
        h_ssm = h_ssm + x * 1e-9
        gate  = gate  + x * 1e-9
        h_sel = torch.mul(h_ssm.clone(), gate.clone())

        # ---- è¾“å‡ºæŠ•å½± + æ®‹å·® ----
        h_out = self.out_proj(h_sel)
        return x + h_out

class ResidualMambaCrossBlock(nn.Module):
    """
    è§£ç å™¨çš„åŸºæœ¬å—ï¼š
    - è‡ªèº«è·¯å¾„ä½¿ç”¨ MambaLikeBlock4Dï¼ˆé˜¶æ®µæ€§ SSM è¿‘ä¼¼ï¼Œè‡ªå›žå½’å› æžœï¼‰
    - ç„¶åŽåšä¸€æ¬¡äº¤å‰æ³¨æ„åŠ›ï¼ˆå¯¹ç¼–ç å™¨ç‰¹å¾ï¼‰ï¼Œå†æŽ¥ MLP
    æ¯æ­¥éƒ½æœ‰æ®‹å·®ï¼›äº¤å‰æ³¨æ„åŠ›ä¸Ž MLP å‰ç½® LayerNormã€‚
    """
    def __init__(self, n_state: int, n_head: int, d_conv: int = 3, ssm_kernel: int = 24):
        super().__init__()
        self.mamba = MambaLikeBlock4D(n_state, d_conv=d_conv, ssm_kernel=ssm_kernel)
        self.cross_attn = MultiHeadAttention(n_state, n_head)
        self.cross_ln = LayerNorm4D(n_state)   # â† ç”¨æˆ‘ä»¬åˆšå†™çš„è¿™ä¸ª

        n_mlp = n_state * 4
        self.mlp = nn.Sequential(
            Linear(n_state, n_mlp), nn.SiLU(), Linear(n_mlp, n_state)
        )
        self.mlp_ln = LayerNorm4D(n_state)

    def set_ssm_parameters(self, alpha: Tensor, beta: Tensor, theta: Tensor) -> None:
        self.mamba.set_ssm_parameters(alpha, beta, theta)

    def forward(self, x: Tensor, xa: Tensor) -> Tensor:
        # Mamba è‡ªèº«è·¯å¾„ï¼ˆå†…éƒ¨è‡ªå¸¦æ®‹å·®ï¼‰
        x = self.mamba(x)
        x = x + x * 1e-9
        # äº¤å‰æ³¨æ„åŠ› + æ®‹å·®
        x = x + self.cross_attn(self.cross_ln(x), xa)
        x = x + x * 1e-9
        # MLP + æ®‹å·®
        x = x + self.mlp(self.mlp_ln(x))
        x = x + x * 1e-9
        return x
    
class Decoder(nn.Module):
    """
    åŸºäºŽ Mamba è‡ªæ³¨æ„ + äº¤å‰æ³¨æ„åŠ› çš„è§£ç å™¨ï¼Œå®žçŽ°ä¸Ž Whisper ç±»ä¼¼çš„ç»“æž„ï¼š
    - token embedding + learnable pos embedding
    - å¤šå±‚ (Mamba + CrossAttn + MLP)
    - æœ€åŽ LayerNorm ä¸Žè¯è¡¨æŠ•å½±ï¼ˆæƒé‡å…±äº«ï¼‰
    å½¢çŠ¶çº¦å®š: æ–‡æœ¬å¼ é‡ä¿æŒ 4D: (B, C, T, 1)
    """
    def __init__(self, n_vocab: int, n_ctx: int, n_state: int, n_head: int, n_layer: int,
                 d_conv: int = 3, ssm_kernel: int = 24):
        super().__init__()
        self.n_state = n_state
        self.n_ctx = n_ctx
        self.n_vocab = n_vocab

        # è®­ç»ƒæ—¶çš„ token embedding
        self.token_emb = nn.Embedding(n_vocab, n_state)

        # è®­ç»ƒæ—¶çš„å¯å­¦ä¹ ä½ç½®å‘é‡
        self.positional_embedding = nn.Parameter(torch.empty(n_ctx, n_state))
        nn.init.normal_(self.positional_embedding, mean=0.0, std=0.02)

        # è®­ç»ƒæ—¶çš„è¾“å‡ºåˆ° vocabï¼ˆéƒ¨ç½²çš„æ—¶å€™å¯ä»¥åªåœ¨ CPU ç”¨ï¼‰
        self.out_proj = Conv1x1NoUnsqueeze(n_state, n_vocab, kernel_size=1, bias=False)

        self.blocks = nn.ModuleList([
            ResidualMambaCrossBlock(n_state, n_head, d_conv=d_conv, ssm_kernel=ssm_kernel)
            for _ in range(n_layer)
        ])
        self.ln = LayerNorm4D(n_state)

        # å›ºå®š 4D shapeï¼ˆç»™ Hailo encoder ç”¨çš„ï¼Œä¸å½±å“ decoder_coreï¼‰
        self.fixed_B = 1
        self.fixed_C = n_state
        self.fixed_T = n_ctx
        self.register_buffer(
            "text_shape_4d",
            torch.tensor([self.fixed_B, self.fixed_C, self.fixed_T, 1], dtype=torch.int64),
            persistent=False
        )

    def set_ssm_parameters(self, alphas: Tensor, betas: Tensor, thetas: Tensor) -> None:
        if alphas.shape[0] != len(self.blocks):
            raise ValueError("alphas length must match number of decoder blocks")
        if betas.shape[0] != len(self.blocks) or thetas.shape[0] != len(self.blocks):
            raise ValueError("betas/thetas length must match number of decoder blocks")
        for i, block in enumerate(self.blocks):
            block.set_ssm_parameters(alphas[i], betas[i], thetas[i])

    def forward(self, token_ids: Tensor, xa: Tensor) -> Tensor:
        """
        è®­ç»ƒ/çº¯ PyTorch æŽ¨ç†æ—¶ä½¿ç”¨ï¼š
        token_ids: (B, T)  int64
        xa        : encoder features (B, C, T_a, 1)
        """
        if token_ids.dim() != 2:
            raise ValueError("token_ids should be (B, T)")

        B, Tt = token_ids.shape

        # 1) token embedding
        x = self.token_emb(token_ids)             # (B, T, C)
        x = x.permute(0, 2, 1).unsqueeze(-1)      # (B, C, T, 1)

        # 2) åŠ å¯å­¦ä¹ ä½ç½®å‘é‡
        pos = self.positional_embedding[:Tt, :].T[None, :, :].unsqueeze(-1)
        pos = pos.to(dtype=x.dtype, device=x.device)
        x = x + pos

        # 3) Mamba + CrossAttn + MLP blocks
        for block in self.blocks:
            x = block(x, xa)

        x = self.ln(x)

        # 4) è®­ç»ƒæ—¶ç›´æŽ¥è¾“å‡º logits
        logits = self.out_proj(x)                 # (B, vocab, T, 1)
        return logits

# class DecoderCore(nn.Module):
#     """
#     éƒ¨ç½²åˆ° Hailo çš„ç²¾ç®€ç‰ˆ Decoderï¼š
#     - ä¸åš token embedding
#     - ä¸åšä½ç½®å‘é‡
#     - ä¸åš out_proj åˆ° vocab
#     åªåš:
#     - å¤šå±‚ (Mamba + CrossAttn + MLP)
#     - æœ€åŽ LayerNorm
#     è¾“å…¥ x å¿…é¡»å·²ç»æ˜¯ (embedding + pos) ä¹‹åŽçš„ç‰¹å¾ã€‚
#     """
#     def __init__(self, decoder: Decoder):
#         super().__init__()
#         self.blocks = decoder.blocks
#         self.ln = decoder.ln

#     def forward(self, x: Tensor, xa: Tensor) -> Tensor:
#         """
#         x : (B, C, T, 1)  å·²ç»åŠ å¥½ embedding + pos çš„ç‰¹å¾
#         xa: (B, C, T_a, 1) encoder è¾“å‡º
#         """
#         if x.dim() != 4:
#             raise ValueError("x should be (B,C,T,1)")
#         if xa.dim() != 4:
#             raise ValueError("xa should be (B,C,T_a,1)")

#         for block in self.blocks:
#             x = block(x, xa)

#         x = self.ln(x)

#         # å° hack é˜²æ­¢ Hailo æŠ˜å æŽ‰
#         x = x.clone()
#         x = x + 0
#         return x
    
# class WhisperHailoModel(nn.Module):
    # def __init__(self, dims):
    #     super().__init__()
    #     self.dims = dims

    #     # è¯­éŸ³ç¼–ç å™¨
    #     self.encoder = AudioEncoder(
    #         n_mels=dims.n_mels,
    #         n_ctx=dims.n_audio_ctx,
    #         n_state=dims.n_audio_state,
    #         n_head=dims.n_audio_head,
    #         n_layer=dims.n_audio_layer,
    #     )

    #     # æ–‡æœ¬è§£ç å™¨ï¼ˆMamba + CrossAttentionï¼‰
    #     self.decoder = Decoder(
    #         n_vocab=dims.n_vocab,
    #         n_ctx=dims.n_text_ctx,
    #         n_state=dims.n_text_state,
    #         n_head=dims.n_text_head,
    #         n_layer=dims.n_text_layer,
    #     )

    # def embed_audio(self, mel: torch.Tensor) -> torch.Tensor:
    #     """ç¼–ç éŸ³é¢‘ç‰¹å¾ -> (B, C, T_audio, 1)"""
    #     return self.encoder(mel)

    # def logits(self, onehot: torch.Tensor, audio_features: torch.Tensor) -> torch.Tensor:
    #     """è§£ç  logits"""
    #     return self.decoder(onehot, audio_features)

    # def forward(self, mel: torch.Tensor, onehot: torch.Tensor) -> torch.Tensor:
    #     audio_features = self.encoder(mel)
    #     logits = self.decoder(onehot, audio_features)
    #     return logits